

Windows:   ã€c++éƒ¨ç½²yolov10è¯¦ç»†æ•™ç¨‹ï¼Œyolov10 cppéƒ¨ç½²-å“”å“©å“”å“©ã€‘ [https://b23.tv/yTYjU3V](about:blank)

Linux:  [https://github.com/Aimol-l/OrtInference](about:blank)  
 

## Yolov10ç½‘ç»œè¯¦è§£
 ã€ç”¨30åˆ†é’Ÿå¸¦ä½ ä»ä»£ç è§’åº¦ç†è§£YOLOv10ï¼åŸºæœ¬åŸç†+ä»£ç å®æˆ˜é€šé€šéƒ½æœ‰ï¼-ç¥ç»ç½‘ç»œ/è®¡ç®—æœºè§†è§‰/ç›®æ ‡æ£€æµ‹ã€‘ [https://www.bilibili.com/video/BV1Pr421A7oV/?share_source=copy_web&vd_source=15777ee1ddccdb98cdd99268c52b0741](about:blank)



![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726738182293-aa4bb910-2eeb-4991-a977-0bcd919c3f8c.png)

å¯ä»¥çœ‹åˆ°Yolov10å“åº”é€Ÿåº¦å’Œç²¾åº¦æ˜¯å¾ˆé«˜çš„ï¼Œå‚æ•°é‡æ›´å°‘ï¼Œ

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726738425911-4c17f102-ccae-40fe-be39-a01b47d0ec69.png)

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726738930072-19a4acc4-0330-4881-ac7a-b6ddbdbd3957.png)

```yaml
yolov10-main
â”œâ”€â”€ datasets: å­˜æ”¾æ•°æ®é›†çš„ç›®å½•ã€‚
â”œâ”€â”€ docker: Dockerç›¸å…³æ–‡ä»¶ï¼Œç”¨äºå®¹å™¨åŒ–éƒ¨ç½²ã€‚
â”‚   â”œâ”€â”€ Dockerfile: ç”¨äºæ„å»ºé»˜è®¤Dockeré•œåƒã€‚
â”‚   â”œâ”€â”€ Dockerfile-arm64: ç”¨äºæ„å»ºARM64æ¶æ„çš„Dockeré•œåƒã€‚
â”‚   â”œâ”€â”€ Dockerfile-conda: ç”¨äºæ„å»ºåŒ…å«Condaç¯å¢ƒçš„Dockeré•œåƒã€‚
â”‚   â”œâ”€â”€ Dockerfile-cpu: ç”¨äºæ„å»ºä»…æ”¯æŒCPUçš„Dockeré•œåƒã€‚
â”‚   â”œâ”€â”€ Dockerfile-jetson: ç”¨äºæ„å»ºNVIDIA Jetsonè®¾å¤‡çš„Dockeré•œåƒã€‚
â”‚   â”œâ”€â”€ Dockerfile-python: ç”¨äºæ„å»ºåŒ…å«Pythonç¯å¢ƒçš„Dockeré•œåƒã€‚
â”‚   â”œâ”€â”€ Dockerfile-runner: ç”¨äºæ„å»ºè¿è¡Œç‰¹å®šä»»åŠ¡çš„Dockeré•œåƒã€‚
â”œâ”€â”€ docs: é¡¹ç›®æ–‡æ¡£ç›®å½•ã€‚
â”‚   â”œâ”€â”€ en: è‹±æ–‡æ–‡æ¡£ç›®å½•ã€‚
â”‚   â”œâ”€â”€ overrides: MkDocsé…ç½®è¦†ç›–ç›®å½•ã€‚
â”‚   â”œâ”€â”€ build_docs.py: æ„å»ºæ–‡æ¡£çš„è„šæœ¬ã€‚
â”‚   â”œâ”€â”€ build_reference.py: æ„å»ºå‚è€ƒæ–‡æ¡£çš„è„šæœ¬ã€‚
â”‚   â”œâ”€â”€ coming_soon_template.md: å³å°†å‘å¸ƒçš„æ¨¡æ¿æ–‡æ¡£ã€‚
â”‚   â”œâ”€â”€ mkdocs_github_authors.yaml: MkDocsé…ç½®æ–‡ä»¶ï¼ŒåŒ…å«GitHubä½œè€…ä¿¡æ¯ã€‚
â”‚   â””â”€â”€ README.md: æ–‡æ¡£ç›®å½•çš„è¯´æ˜æ–‡ä»¶ã€‚
â”œâ”€â”€ examples: ç¤ºä¾‹ä»£ç ç›®å½•ã€‚
â”‚   â”œâ”€â”€ YOLOv8-CPP-Inference: YOLOv8 C++æ¨ç†ç¤ºä¾‹ã€‚
â”‚   â”œâ”€â”€ YOLOv8-LibTorch-CPP-Inference: YOLOv8 LibTorch C++æ¨ç†ç¤ºä¾‹ã€‚
â”‚   â”œâ”€â”€ YOLOv8-ONNXRuntime: YOLOv8 ONNXRuntimeæ¨ç†ç¤ºä¾‹ã€‚
â”‚   â”œâ”€â”€ YOLOv8-ONNXRuntime-CPP: YOLOv8 ONNXRuntime C++æ¨ç†ç¤ºä¾‹ã€‚
â”‚   â”œâ”€â”€ YOLOv8-ONNXRuntime-Rust: YOLOv8 ONNXRuntime Rustæ¨ç†ç¤ºä¾‹ã€‚
â”‚   â”œâ”€â”€ YOLOv8-OpenCV-int8-tflite-Python: YOLOv8 OpenCV int8 tflite Pythonæ¨ç†ç¤ºä¾‹ã€‚
â”‚   â”œâ”€â”€ YOLOv8-OpenCV-ONNX-Python: YOLOv8 OpenCV ONNX Pythonæ¨ç†ç¤ºä¾‹ã€‚
â”‚   â”œâ”€â”€ YOLOv8-Region-Counter: YOLOv8åŒºåŸŸè®¡æ•°ç¤ºä¾‹ã€‚
â”‚   â”œâ”€â”€ YOLOv8-SAHI-Inference-Video: YOLOv8 SAHIè§†é¢‘æ¨ç†ç¤ºä¾‹ã€‚
â”‚   â”œâ”€â”€ YOLOv8-Segmentation-ONNXRuntime-Python: YOLOv8åˆ†å‰² ONNXRuntime Pythonæ¨ç†ç¤ºä¾‹ã€‚
â”‚   â”œâ”€â”€ heatmaps.ipynb: çƒ­å›¾ç”Ÿæˆç¤ºä¾‹ã€‚
â”‚   â”œâ”€â”€ hub.ipynb: æ¨¡å‹é›†çº¿å™¨ç¤ºä¾‹ã€‚
â”‚   â”œâ”€â”€ object_counting.ipynb: ç‰©ä½“è®¡æ•°ç¤ºä¾‹ã€‚
â”‚   â”œâ”€â”€ object_tracking.ipynb: ç‰©ä½“è·Ÿè¸ªç¤ºä¾‹ã€‚
â”‚   â””â”€â”€ tutorial.ipynb: æ•™ç¨‹ç¤ºä¾‹ã€‚
â”œâ”€â”€ figures: å­˜æ”¾é¡¹ç›®ç›¸å…³çš„å›¾åƒæ–‡ä»¶ã€‚
â”‚   â”œâ”€â”€ latency.svg: å»¶è¿Ÿå›¾ã€‚
â”‚   â”œâ”€â”€ params.svg: å‚æ•°å›¾ã€‚
â”œâ”€â”€ models: å­˜æ”¾æ¨¡å‹æ–‡ä»¶çš„ç›®å½•ã€‚
â”‚   â”œâ”€â”€ yolov10n.pt: YOLOv10næ¨¡å‹æ–‡ä»¶ã€‚
â”œâ”€â”€ runs: å­˜æ”¾è¿è¡Œç»“æœçš„ç›®å½•ã€‚
â”‚   â”œâ”€â”€ detect: æ£€æµ‹ç»“æœã€‚
â”‚   â”œâ”€â”€ train5: ç¬¬äº”æ¬¡è®­ç»ƒç»“æœã€‚
â”‚   â”œâ”€â”€ train6: ç¬¬å…­æ¬¡è®­ç»ƒç»“æœã€‚
â”‚   â”œâ”€â”€ val: éªŒè¯ç»“æœã€‚
â”œâ”€â”€ tests: æµ‹è¯•ä»£ç ç›®å½•ã€‚
â”‚   â”œâ”€â”€ conftest.py: æµ‹è¯•é…ç½®æ–‡ä»¶ã€‚
â”‚   â”œâ”€â”€ test_cli.py: CLIæµ‹è¯•è„šæœ¬ã€‚
â”‚   â”œâ”€â”€ test_cuda.py: CUDAæµ‹è¯•è„šæœ¬ã€‚
â”‚   â”œâ”€â”€ test_engine.py: å¼•æ“æµ‹è¯•è„šæœ¬ã€‚
â”‚   â”œâ”€â”€ test_explorer.py: æ¢ç´¢æµ‹è¯•è„šæœ¬ã€‚
â”‚   â”œâ”€â”€ test_integrations.py: é›†æˆæµ‹è¯•è„šæœ¬ã€‚
â”‚   â”œâ”€â”€ test_python.py: Pythonæµ‹è¯•è„šæœ¬ã€‚
â”œâ”€â”€ ultralytics: YOLOv10æ ¸å¿ƒä»£ç ç›®å½•ã€‚
â”‚   â”œâ”€â”€ assets: èµ„äº§æ–‡ä»¶ç›®å½•ã€‚
â”‚   â”œâ”€â”€ cfg: é…ç½®æ–‡ä»¶ç›®å½•ã€‚
â”‚   â”œâ”€â”€ data: æ•°æ®æ–‡ä»¶ç›®å½•ã€‚
â”‚   â”œâ”€â”€ engine: å¼•æ“ä»£ç ç›®å½•ã€‚
â”‚   â”œâ”€â”€ hub: æ¨¡å‹é›†çº¿å™¨ç›®å½•ã€‚
â”‚   â”œâ”€â”€ models: æ¨¡å‹ä»£ç ç›®å½•ã€‚
â”‚   â”œâ”€â”€ nn: ç¥ç»ç½‘ç»œä»£ç ç›®å½•ã€‚
â”‚   â”œâ”€â”€ solutions: è§£å†³æ–¹æ¡ˆç›®å½•ã€‚
â”‚   â”œâ”€â”€ trackers: è·Ÿè¸ªå™¨ç›®å½•ã€‚
â”‚   â”œâ”€â”€ utils: å·¥å…·å‡½æ•°ç›®å½•ã€‚
â”‚   â””â”€â”€ __init__.py: åˆå§‹åŒ–æ–‡ä»¶ã€‚
â”œâ”€â”€ ultralytics.egg-info: é¡¹ç›®å®‰è£…ä¿¡æ¯ç›®å½•ã€‚
â”‚   â”œâ”€â”€ dependency_links.txt: ä¾èµ–é“¾æ¥ä¿¡æ¯ã€‚
â”‚   â”œâ”€â”€ entry_points.txt: å…¥å£ç‚¹ä¿¡æ¯ã€‚
â”‚   â”œâ”€â”€ PKG-INFO: åŒ…ä¿¡æ¯ã€‚
â”‚   â”œâ”€â”€ requires.txt: ä¾èµ–é¡¹ä¿¡æ¯ã€‚
â”‚   â”œâ”€â”€ SOURCES.txt: æºæ–‡ä»¶ä¿¡æ¯ã€‚
â”‚   â””â”€â”€ top_level.txt: é¡¶çº§æ¨¡å—ä¿¡æ¯ã€‚
â”œâ”€â”€ .gitignore: æŒ‡å®šåº”å¿½ç•¥çš„æ–‡ä»¶å’Œç›®å½•ã€‚
â”œâ”€â”€ .pre-commit-config.yaml: é…ç½®pre-commité’©å­çš„æ–‡ä»¶ã€‚
â”œâ”€â”€ 1.txt: æœªçŸ¥ç”¨é€”æ–‡ä»¶ã€‚
â”œâ”€â”€ CONTRIBUTING.md: è´¡çŒ®æŒ‡å—ï¼ŒæŒ‡å¯¼ç”¨æˆ·å¦‚ä½•ä¸ºé¡¹ç›®åšè´¡çŒ®ã€‚
â”œâ”€â”€ LICENSE: åŒ…å«é¡¹ç›®çš„è®¸å¯ä¿¡æ¯ã€‚
â”œâ”€â”€ mkdocs.yml: MkDocsé…ç½®æ–‡ä»¶ï¼Œç”¨äºç”Ÿæˆé¡¹ç›®æ–‡æ¡£ã€‚
â”œâ”€â”€ pyproject.toml: é¡¹ç›®é…ç½®æ–‡ä»¶ï¼ŒåŒ…æ‹¬ä¾èµ–é¡¹å’Œå·¥å…·é…ç½®ã€‚
â”œâ”€â”€ README.md: æä¾›é¡¹ç›®æ¦‚è¿°å’Œä½¿ç”¨è¯´æ˜ã€‚
â””â”€â”€ requirements.txt: åˆ—å‡ºé¡¹ç›®æ‰€éœ€çš„Pythonä¾èµ–åº“ã€‚

```

```yaml
ultralytics
â”œâ”€â”€ assets: å­˜æ”¾èµ„äº§æ–‡ä»¶çš„ç›®å½•ã€‚
â”œâ”€â”€ cfg: é…ç½®æ–‡ä»¶ç›®å½•ã€‚
â”‚   â””â”€â”€ default.yaml: é»˜è®¤é…ç½®æ–‡ä»¶ï¼ŒåŒ…å«è®­ç»ƒå’Œæµ‹è¯•çš„å‚æ•°è®¾ç½®ã€‚
â”œâ”€â”€ data: æ•°æ®æ–‡ä»¶ç›®å½•ã€‚
â”‚   â”œâ”€â”€ __init__.py: åˆå§‹åŒ–æ•°æ®æ¨¡å—ã€‚
â”‚   â”œâ”€â”€ annotator.py: æ•°æ®æ³¨é‡Šå·¥å…·ã€‚
â”‚   â”œâ”€â”€ augment.py: æ•°æ®å¢å¼ºå·¥å…·ã€‚
â”‚   â”œâ”€â”€ base.py: æ•°æ®å¤„ç†çš„åŸºç¡€ç±»å’Œå‡½æ•°ã€‚
â”‚   â”œâ”€â”€ build.py: æ•°æ®æ„å»ºå·¥å…·ã€‚
â”‚   â”œâ”€â”€ converter.py: æ•°æ®è½¬æ¢å·¥å…·ã€‚
â”‚   â”œâ”€â”€ dataset.py: æ•°æ®é›†å¤„ç†å·¥å…·ã€‚
â”‚   â”œâ”€â”€ loaders.py: æ•°æ®åŠ è½½å·¥å…·ã€‚
â”‚   â”œâ”€â”€ split_dota.py: ä¸“ç”¨äºDOTAæ•°æ®é›†çš„åˆ†å‰²å·¥å…·ã€‚
â”‚   â””â”€â”€ utils.py: æ•°æ®å¤„ç†çš„è¾…åŠ©å·¥å…·ã€‚
â”œâ”€â”€ engine: å¼•æ“ä»£ç ç›®å½•ã€‚
â”‚   â”œâ”€â”€ __init__.py: åˆå§‹åŒ–å¼•æ“æ¨¡å—ã€‚
â”‚   â”œâ”€â”€ exporter.py: å¯¼å‡ºæ¨¡å‹çš„å·¥å…·ã€‚
â”‚   â”œâ”€â”€ model.py: å®šä¹‰æ¨¡å‹ç»“æ„çš„æ–‡ä»¶ã€‚
â”‚   â”œâ”€â”€ predictor.py: é¢„æµ‹åŠŸèƒ½çš„å®ç°ã€‚
â”‚   â”œâ”€â”€ results.py: å¤„ç†å’Œå±•ç¤ºç»“æœçš„å·¥å…·ã€‚
â”‚   â”œâ”€â”€ trainer.py: æ¨¡å‹è®­ç»ƒçš„å·¥å…·ã€‚
â”‚   â”œâ”€â”€ tuner.py: æ¨¡å‹è°ƒä¼˜å·¥å…·ã€‚
â”‚   â””â”€â”€ validator.py: æ¨¡å‹éªŒè¯å·¥å…·ã€‚
â”œâ”€â”€ hub: æ¨¡å‹é›†çº¿å™¨ç›®å½•ã€‚
â”‚   â”œâ”€â”€ __init__.py: åˆå§‹åŒ–é›†çº¿å™¨æ¨¡å—ã€‚
â”‚   â”œâ”€â”€ auth.py: å¤„ç†èº«ä»½éªŒè¯çš„å·¥å…·ã€‚
â”‚   â”œâ”€â”€ session.py: ç®¡ç†ä¼šè¯çš„å·¥å…·ã€‚
â”‚   â””â”€â”€ utils.py: é›†çº¿å™¨æ¨¡å—çš„è¾…åŠ©å·¥å…·ã€‚
â”œâ”€â”€ models: æ¨¡å‹ä»£ç ç›®å½•ã€‚
â”‚   â”œâ”€â”€ fastsam: å­˜æ”¾FastSAMæ¨¡å‹ç›¸å…³ä»£ç çš„ç›®å½•ã€‚
â”‚   â”œâ”€â”€ nas: å­˜æ”¾NASæ¨¡å‹ç›¸å…³ä»£ç çš„ç›®å½•ã€‚
â”‚   â”œâ”€â”€ rtdetr: å­˜æ”¾RT-DETRæ¨¡å‹ç›¸å…³ä»£ç çš„ç›®å½•ã€‚
â”‚   â”œâ”€â”€ sam: å­˜æ”¾SAMæ¨¡å‹ç›¸å…³ä»£ç çš„ç›®å½•ã€‚
â”‚   â”œâ”€â”€ utils: å­˜æ”¾æ¨¡å‹å·¥å…·å‡½æ•°çš„ç›®å½•ã€‚
â”‚   â””â”€â”€ yolo: YOLOæ¨¡å‹ç›¸å…³ä»£ç çš„ç›®å½•ã€‚
â”‚       â”œâ”€â”€ __init__.py: åˆå§‹åŒ–YOLOæ¨¡å‹æ¨¡å—ã€‚
â”‚       â”œâ”€â”€ model.py: å®šä¹‰YOLOæ¨¡å‹ç»“æ„çš„æ–‡ä»¶ã€‚
â”‚       â”œâ”€â”€ predict.py: YOLOæ¨¡å‹çš„é¢„æµ‹å®ç°ã€‚
â”‚       â”œâ”€â”€ train.py: YOLOæ¨¡å‹çš„è®­ç»ƒå®ç°ã€‚
â”‚       â””â”€â”€ val.py: YOLOæ¨¡å‹çš„éªŒè¯å®ç°ã€‚
â”œâ”€â”€ nn: ç¥ç»ç½‘ç»œä»£ç ç›®å½•ã€‚
â”‚   â”œâ”€â”€ __init__.py: åˆå§‹åŒ–ç¥ç»ç½‘ç»œæ¨¡å—ã€‚
â”‚   â”œâ”€â”€ modules: å­˜æ”¾ç¥ç»ç½‘ç»œæ¨¡å—çš„ç›®å½•ã€‚
â”‚       â””â”€â”€ __init__.py: åˆå§‹åŒ–æ¨¡å—ç›®å½•ã€‚
â”‚   â”œâ”€â”€ autobackend.py: è‡ªåŠ¨é€‰æ‹©åç«¯çš„å·¥å…·ã€‚
â”‚   â””â”€â”€ tasks.py: å®šä¹‰ç¥ç»ç½‘ç»œä»»åŠ¡çš„æ–‡ä»¶ã€‚
â”œâ”€â”€ solutions: è§£å†³æ–¹æ¡ˆç›®å½•ã€‚
â”‚   â”œâ”€â”€ __init__.py: åˆå§‹åŒ–è§£å†³æ–¹æ¡ˆæ¨¡å—ã€‚
â”‚   â”œâ”€â”€ ai_gym.py: AIå¥èº«æˆ¿ç›¸å…³è§£å†³æ–¹æ¡ˆã€‚
â”‚   â”œâ”€â”€ distance_calculation.py: è·ç¦»è®¡ç®—ç›¸å…³è§£å†³æ–¹æ¡ˆã€‚
â”‚   â”œâ”€â”€ heatmap.py: çƒ­å›¾ç”Ÿæˆè§£å†³æ–¹æ¡ˆã€‚
â”‚   â”œâ”€â”€ object_counter.py: ç‰©ä½“è®¡æ•°è§£å†³æ–¹æ¡ˆã€‚
â”‚   â””â”€â”€ speed_estimation.py: é€Ÿåº¦ä¼°ç®—è§£å†³æ–¹æ¡ˆã€‚
â”œâ”€â”€ trackers: è·Ÿè¸ªå™¨ç›®å½•ã€‚
â”‚   â”œâ”€â”€ __init__.py: åˆå§‹åŒ–è·Ÿè¸ªå™¨æ¨¡å—ã€‚
â”‚   â”œâ”€â”€ basetrack.py: åŸºç¡€è·Ÿè¸ªå™¨å®ç°ã€‚
â”‚   â”œâ”€â”€ bot_sort.py: BOT SORTè·Ÿè¸ªå™¨å®ç°ã€‚
â”‚   â”œâ”€â”€ byte_tracker.py: BYTEè·Ÿè¸ªå™¨å®ç°ã€‚
â”‚   â”œâ”€â”€ README.md: è·Ÿè¸ªå™¨æ¨¡å—è¯´æ˜æ–‡ä»¶ã€‚
â”‚   â””â”€â”€ track.py: è·Ÿè¸ªå™¨çš„ä¸»è¦å®ç°æ–‡ä»¶ã€‚
â”œâ”€â”€ utils: å·¥å…·å‡½æ•°ç›®å½•ã€‚
â”‚   â”œâ”€â”€ __init__.py: åˆå§‹åŒ–å·¥å…·æ¨¡å—ã€‚
â”‚   â”œâ”€â”€ autobatch.py: è‡ªåŠ¨æ‰¹å¤„ç†å·¥å…·ã€‚
â”‚   â”œâ”€â”€ benchmarks.py: åŸºå‡†æµ‹è¯•å·¥å…·ã€‚
â”‚   â”œâ”€â”€ checks.py: æ£€æŸ¥å·¥å…·ã€‚
â”‚   â”œâ”€â”€ dist.py: åˆ†å¸ƒå¼è®¡ç®—å·¥å…·ã€‚
â”‚   â”œâ”€â”€ downloads.py: ä¸‹è½½å·¥å…·ã€‚
â”‚   â”œâ”€â”€ errors.py: é”™è¯¯å¤„ç†å·¥å…·ã€‚
â”‚   â”œâ”€â”€ files.py: æ–‡ä»¶å¤„ç†å·¥å…·ã€‚
â”‚   â”œâ”€â”€ instance.py: å®ä¾‹åŒ–å·¥å…·ã€‚
â”‚   â”œâ”€â”€ loss.py: æŸå¤±è®¡ç®—å·¥å…·ã€‚
â”‚   â”œâ”€â”€ metrics.py: è¯„ä¼°æŒ‡æ ‡å·¥å…·ã€‚
â”‚   â”œâ”€â”€ ops.py: æ“ä½œå‡½æ•°å·¥å…·ã€‚
â”‚   â”œâ”€â”€ patches.py: è¡¥ä¸å·¥å…·ã€‚
â”‚   â”œâ”€â”€ plotting.py: ç»˜å›¾å·¥å…·ã€‚
â”‚   â”œâ”€â”€ tal.py: TALç›¸å…³å·¥å…·ã€‚
â”‚   â”œâ”€â”€ torch_utils.py: PyTorchå·¥å…·å‡½æ•°ã€‚
â”‚   â”œâ”€â”€ triton.py: Tritonç›¸å…³å·¥å…·ã€‚
â”‚   â””â”€â”€ tuner.py: è°ƒä¼˜å·¥å…·ã€‚
```

é»˜è®¤å‚æ•°ï¼š

```yaml
# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# Default training settings and hyperparameters for medium-augmentation COCO training

task: detect # (str) YOLO task, i.e. detect, segment, classify, pose
mode: train # (str) YOLO mode, i.e. train, val, predict, export, track, benchmark

# Train settings -------------------------------------------------------------------------------------------------------
model: # (str, optional) path to model file, i.e. yolov8n.pt, yolov8n.yaml
data: # (str, optional) path to data file, i.e. coco128.yaml
epochs: 100 # (int) number of epochs to train for
time: # (float, optional) number of hours to train for, overrides epochs if supplied
patience: 100 # (int) epochs to wait for no observable improvement for early stopping of training
batch: 16 # (int) number of images per batch (-1 for AutoBatch)
imgsz: 640 # (int | list) input images size as int for train and val modes, or list[w,h] for predict and export modes
save: True # (bool) save train checkpoints and predict results
save_period: -1 # (int) Save checkpoint every x epochs (disabled if < 1)
val_period: 1 # (int) Validation every x epochs
cache: False # (bool) True/ram, disk or False. Use cache for data loading
device: # (int | str | list, optional) device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu
workers: 8 # (int) number of worker threads for data loading (per RANK if DDP)
project: # (str, optional) project name
name: # (str, optional) experiment name, results saved to 'project/name' directory
exist_ok: False # (bool) whether to overwrite existing experiment
pretrained: True # (bool | str) whether to use a pretrained model (bool) or a model to load weights from (str)
optimizer: auto # (str) optimizer to use, choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]
verbose: True # (bool) whether to print verbose output
seed: 0 # (int) random seed for reproducibility
deterministic: True # (bool) whether to enable deterministic mode
single_cls: False # (bool) train multi-class data as single-class
rect: False # (bool) rectangular training if mode='train' or rectangular validation if mode='val'
cos_lr: False # (bool) use cosine learning rate scheduler
close_mosaic: 10 # (int) disable mosaic augmentation for final epochs (0 to disable)
resume: False # (bool) resume training from last checkpoint
amp: True # (bool) Automatic Mixed Precision (AMP) training, choices=[True, False], True runs AMP check
fraction: 1.0 # (float) dataset fraction to train on (default is 1.0, all images in train set)
profile: False # (bool) profile ONNX and TensorRT speeds during training for loggers
freeze: None # (int | list, optional) freeze first n layers, or freeze list of layer indices during training
multi_scale: False # (bool) Whether to use multiscale during training
# Segmentation
overlap_mask: True # (bool) masks should overlap during training (segment train only)
mask_ratio: 4 # (int) mask downsample ratio (segment train only)
# Classification
dropout: 0.0 # (float) use dropout regularization (classify train only)

# Val/Test settings ----------------------------------------------------------------------------------------------------
val: True # (bool) validate/test during training
split: val # (str) dataset split to use for validation, i.e. 'val', 'test' or 'train'
save_json: False # (bool) save results to JSON file
save_hybrid: False # (bool) save hybrid version of labels (labels + additional predictions)
conf: # (float, optional) object confidence threshold for detection (default 0.25 predict, 0.001 val)
iou: 0.7 # (float) intersection over union (IoU) threshold for NMS
max_det: 300 # (int) maximum number of detections per image
half: False # (bool) use half precision (FP16)
dnn: False # (bool) use OpenCV DNN for ONNX inference
plots: True # (bool) save plots and images during train/val

# Predict settings -----------------------------------------------------------------------------------------------------
source: # (str, optional) source directory for images or videos
vid_stride: 1 # (int) video frame-rate stride
stream_buffer: False # (bool) buffer all streaming frames (True) or return the most recent frame (False)
visualize: False # (bool) visualize model features
augment: False # (bool) apply image augmentation to prediction sources
agnostic_nms: False # (bool) class-agnostic NMS
classes: # (int | list[int], optional) filter results by class, i.e. classes=0, or classes=[0,2,3]
retina_masks: False # (bool) use high-resolution segmentation masks
embed: # (list[int], optional) return feature vectors/embeddings from given layers

# Visualize settings ---------------------------------------------------------------------------------------------------
show: False # (bool) show predicted images and videos if environment allows
save_frames: False # (bool) save predicted individual video frames
save_txt: False # (bool) save results as .txt file
save_conf: False # (bool) save results with confidence scores
save_crop: False # (bool) save cropped images with results
show_labels: True # (bool) show prediction labels, i.e. 'person'
show_conf: True # (bool) show prediction confidence, i.e. '0.99'
show_boxes: True # (bool) show prediction boxes
line_width: # (int, optional) line width of the bounding boxes. Scaled to image size if None.

# Export settings ------------------------------------------------------------------------------------------------------
format: torchscript # (str) format to export to, choices at https://docs.ultralytics.com/modes/export/#export-formats
keras: False # (bool) use Kera=s
optimize: False # (bool) TorchScript: optimize for mobile
int8: False # (bool) CoreML/TF INT8 quantization
dynamic: False # (bool) ONNX/TF/TensorRT: dynamic axes
simplify: False # (bool) ONNX: simplify model using `onnxslim`
opset: # (int, optional) ONNX: opset version
workspace: 4 # (int) TensorRT: workspace size (GB)
nms: False # (bool) CoreML: add NMS

# Hyperparameters ------------------------------------------------------------------------------------------------------
lr0: 0.01 # (float) initial learning rate (i.e. SGD=1E-2, Adam=1E-3)
lrf: 0.01 # (float) final learning rate (lr0 * lrf)
momentum: 0.937 # (float) SGD momentum/Adam beta1
weight_decay: 0.0005 # (float) optimizer weight decay 5e-4
warmup_epochs: 3.0 # (float) warmup epochs (fractions ok)
warmup_momentum: 0.8 # (float) warmup initial momentum
warmup_bias_lr: 0.1 # (float) warmup initial bias lr
box: 7.5 # (float) box loss gain
cls: 0.5 # (float) cls loss gain (scale with pixels)
dfl: 1.5 # (float) dfl loss gain
pose: 12.0 # (float) pose loss gain
kobj: 1.0 # (float) keypoint obj loss gain
label_smoothing: 0.0 # (float) label smoothing (fraction)
nbs: 64 # (int) nominal batch size
hsv_h: 0.015 # (float) image HSV-Hue augmentation (fraction)
hsv_s: 0.7 # (float) image HSV-Saturation augmentation (fraction)
hsv_v: 0.4 # (float) image HSV-Value augmentation (fraction)
degrees: 0.0 # (float) image rotation (+/- deg)
translate: 0.1 # (float) image translation (+/- fraction)
scale: 0.5 # (float) image scale (+/- gain)
shear: 0.0 # (float) image shear (+/- deg)
perspective: 0.0 # (float) image perspective (+/- fraction), range 0-0.001
flipud: 0.0 # (float) image flip up-down (probability)
fliplr: 0.5 # (float) image flip left-right (probability)
bgr: 0.0 # (float) image channel BGR (probability)
mosaic: 1.0 # (float) image mosaic (probability)
mixup: 0.0 # (float) image mixup (probability)
copy_paste: 0.0 # (float) segment copy-paste (probability)
auto_augment: randaugment # (str) auto augmentation policy for classification (randaugment, autoaugment, augmix)
erasing: 0.4 # (float) probability of random erasing during classification training (0-1)
crop_fraction: 1.0 # (float) image crop fraction for classification evaluation/inference (0-1)

# Custom config.yaml ---------------------------------------------------------------------------------------------------
cfg: # (str, optional) for overriding defaults.yaml

# Tracker settings ------------------------------------------------------------------------------------------------------
tracker: botsort.yaml # (str) tracker type, choices=[botsort.yaml, bytetrack.yaml]

```

ä¸­æ–‡ç‰ˆï¼š[é»˜è®¤å‚æ•°è§£é‡Š.md](https://www.yuque.com/attachments/yuque/0/2024/md/39216292/1726737234779-e333cfd4-b863-4d8c-ac82-f530c2fad43b.md)

```markdown
| å‚æ•°å       | è¾“å…¥ç±»å‹            | å‚æ•°è§£é‡Š                                                                 |
|--------------|---------------------|--------------------------------------------------------------------------|
| task         | str                 | YOLOæ¨¡å‹çš„ä»»åŠ¡é€‰æ‹©ï¼Œé€‰æ‹©ä½ æ˜¯è¦è¿›è¡Œæ£€æµ‹ã€åˆ†ç±»ç­‰æ“ä½œ                      |
| mode         | str                 | YOLOæ¨¡å¼çš„é€‰æ‹©ï¼Œé€‰æ‹©è¦è¿›è¡Œè®­ç»ƒã€æ¨ç†ã€è¾“å‡ºã€éªŒè¯ç­‰æ“ä½œ                  |
| model        | str/optional        | æ¨¡å‹çš„æ–‡ä»¶ï¼Œå¯ä»¥æ˜¯å®˜æ–¹çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œä¹Ÿå¯ä»¥æ˜¯è®­ç»ƒè‡ªå·±æ¨¡å‹çš„yamlæ–‡ä»¶       |
| data         | str/optional        | æ¨¡å‹çš„åœ°å€ï¼Œå¯ä»¥æ˜¯æ–‡ä»¶çš„åœ°å€ï¼Œä¹Ÿå¯ä»¥æ˜¯é…ç½®å¥½åœ°å€çš„yamlæ–‡ä»¶               |
| epochs       | int                 | è®­ç»ƒçš„è½®æ¬¡ï¼Œå°†ä½ çš„æ•°æ®è¾“å…¥åˆ°æ¨¡å‹é‡Œè¿›è¡Œè®­ç»ƒçš„æ¬¡æ•°                         |
| patience     | int                 | æ—©åœæœºåˆ¶ï¼Œå½“ä½ çš„æ¨¡å‹ç²¾åº¦æ²¡æœ‰æ”¹è¿›äº†å°±æå‰åœæ­¢è®­ç»ƒ                         |
| batch        | int                 | æˆ‘ä»¬è¾“å…¥çš„æ•°æ®é›†ä¼šåˆ†è§£ä¸ºå¤šä¸ªå­é›†ï¼Œä¸€æ¬¡å‘æ¨¡å‹é‡Œè¾“å…¥å¤šå°‘ä¸ªå­é›†             |
| imgsz        | int/list            | è¾“å…¥çš„å›¾ç‰‡çš„å¤§å°ï¼Œå¯ä»¥æ˜¯æ•´æ•°å°±ä»£è¡¨å›¾ç‰‡å°ºå¯¸ä¸ºint*intï¼Œæˆ–è€…liståˆ†åˆ«ä»£è¡¨å®½å’Œé«˜[wï¼Œh] |
| save         | bool                | æ˜¯å¦ä¿å­˜æ¨¡å‹ä»¥åŠé¢„æµ‹ç»“æœ                                                 |
| save_period  | int                 | åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¤šå°‘æ¬¡ä¿å­˜ä¸€æ¬¡æ¨¡å‹æ–‡ä»¶,å°±æ˜¯ç”Ÿæˆçš„ptæ–‡ä»¶                      |
| cache        | bool                | å‚æ•°cacheç”¨äºæ§åˆ¶æ˜¯å¦å¯ç”¨ç¼“å­˜æœºåˆ¶                                         |
| device       | int/str/list/optional | GPUè®¾å¤‡çš„é€‰æ‹©ï¼šcuda device=0 or device=0,1,2,3 or device=cpu             |
| workers      | int                 | å·¥ä½œçš„çº¿ç¨‹ï¼ŒWindowsç³»ç»Ÿä¸€å®šè¦è®¾ç½®ä¸º0å¦åˆ™å¾ˆå¯èƒ½ä¼šå¼•èµ·çº¿ç¨‹æŠ¥é”™             |
| name         | str/optional        | æ¨¡å‹ä¿å­˜çš„åå­—ï¼Œç»“æœä¼šä¿å­˜åˆ°'project/name' ç›®å½•ä¸‹                        |
| exist_ok     | bool                | å¦‚æœæ¨¡å‹å­˜åœ¨çš„æ—¶å€™æ˜¯å¦è¿›è¡Œè¦†ç›–æ“ä½œ                                       |
| pretrained   | bool                | å‚æ•°pretrainedç”¨äºæ§åˆ¶æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹                                 |
| optimizer    | str                 | ä¼˜åŒ–å™¨çš„é€‰æ‹©choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto] |
| verbose      | bool                | ç”¨äºæ§åˆ¶åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­æ˜¯å¦è¾“å‡ºè¯¦ç»†çš„ä¿¡æ¯å’Œæ—¥å¿—                             |
| seed         | int                 | éšæœºæ•°ç§å­ï¼Œæ¨¡å‹ä¸­æ¶‰åŠåˆ°éšæœºçš„æ—¶å€™ï¼Œæ ¹æ®éšæœºæ•°ç§å­è¿›è¡Œç”Ÿæˆ               |
| deterministic| bool                | ç”¨äºæ§åˆ¶æ˜¯å¦å¯ç”¨ç¡®å®šæ€§æ¨¡å¼ï¼Œåœ¨ç¡®å®šæ€§æ¨¡å¼ä¸‹ï¼Œç®—æ³•çš„æ‰§è¡Œå°†å˜å¾—å¯é‡å¤ï¼Œå³ç›¸åŒçš„è¾“å…¥å°†äº§ç”Ÿç›¸åŒçš„è¾“å‡º |
| single_cls   | bool                | æ˜¯å¦æ˜¯å•æ ‡ç­¾è®­ç»ƒ                                                         |
| rect         | bool                | å½“ rect è®¾ç½®ä¸º True æ—¶ï¼Œè¡¨ç¤ºå¯ç”¨çŸ©å½¢è®­ç»ƒæˆ–éªŒè¯ã€‚çŸ©å½¢è®­ç»ƒæˆ–éªŒè¯æ˜¯ä¸€ç§æ•°æ®å¤„ç†æŠ€æœ¯ï¼Œå…¶ä¸­åœ¨è®­ç»ƒæˆ–éªŒè¯è¿‡ç¨‹ä¸­ï¼Œè¾“å…¥æ•°æ®ä¼šè¢«è°ƒæ•´ä¸ºå…·æœ‰ç›¸åŒå®½é«˜æ¯”çš„çŸ©å½¢å½¢çŠ¶ |
| cos_lr       | bool                | æ§åˆ¶æ˜¯å¦ä½¿ç”¨ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦å™¨                                             |
| close_mosaic | int                 | æ§åˆ¶åœ¨æœ€åå‡ ä¸ª epochs ä¸­æ˜¯å¦ç¦ç”¨é©¬èµ›å…‹æ•°æ®å¢å¼º                           |
| resume       | bool                | ç”¨äºä»å…ˆå‰çš„è®­ç»ƒæ£€æŸ¥ç‚¹ï¼ˆcheckpointï¼‰ä¸­æ¢å¤æ¨¡å‹çš„è®­ç»ƒ                     |
| amp          | bool                | ç”¨äºæ§åˆ¶æ˜¯å¦è¿›è¡Œè‡ªåŠ¨æ··åˆç²¾åº¦                                             |
| fraction     | float               | ç”¨äºæŒ‡å®šè®­ç»ƒæ•°æ®é›†çš„ä¸€éƒ¨åˆ†è¿›è¡Œè®­ç»ƒçš„æ¯”ä¾‹ã€‚é»˜è®¤å€¼ä¸º 1.0                    |
| profile      | bool                | ç”¨äºæ§åˆ¶æ˜¯å¦åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯ç”¨ ONNX å’Œ TensorRT çš„æ€§èƒ½åˆ†æ                  |
| freeze       | int/list/optional   | ç”¨äºæŒ‡å®šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å†»ç»“å‰ n å±‚æˆ–æŒ‡å®šå±‚ç´¢å¼•çš„åˆ—è¡¨ï¼Œä»¥é˜²æ­¢å®ƒä»¬çš„æƒé‡æ›´æ–°ã€‚è¿™å¯¹äºè¿ç§»å­¦ä¹ æˆ–ç‰¹å®šå±‚çš„å¾®è°ƒå¾ˆæœ‰ç”¨ |

```

æ¨¡å‹é…ç½®æ–‡ä»¶ï¼š

```yaml
# Parameters
nc: 80 # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024] 

# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8
  - [-1, 6, C2f, [256, True]]
  - [-1, 1, SCDown, [512, 3, 2]] # 5-P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, SCDown, [1024, 3, 2]] # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]] # 9
  - [-1, 1, PSA, [1024]] # 10

# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]] # cat backbone P4
  - [-1, 3, C2f, [512]] # 13

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]] # cat backbone P3
  - [-1, 3, C2f, [256]] # 16 (P3/8-small)

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 13], 1, Concat, [1]] # cat head P4
  - [-1, 3, C2f, [512]] # 19 (P4/16-medium)

  - [-1, 1, SCDown, [512, 3, 2]]
  - [[-1, 10], 1, Concat, [1]] # cat head P5
  - [-1, 3, C2fCIB, [1024, True, True]] # 22 (P5/32-large)

  - [[16, 19, 22], 1, v10Detect, [nc]] # Detect(P3, P4, P5)

```



yolov10s.yaml ä¸‹é¢å°±æ˜¯sï¼Œåç§°æ ¹æ®ä¸åŒå‹å·å®šä¹‰çš„ï¼Œå…¶ä»–éƒ¨åˆ†åŸºæœ¬ä¸€æ ·ï¼Œ

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726738630827-ff007bb1-3bc4-4bd9-84db-5521289e1061.png)



```yaml
# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 80 # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024] # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.50, 1024] # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  m: [0.67, 0.75, 768] # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  l: [1.00, 1.00, 512] # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [1.00, 1.25, 512] # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs

# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8
  - [-1, 6, C2f, [256, True]]
  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]] # 9

# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]] # cat backbone P4
  - [-1, 3, C2f, [512]] # 12

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]] # cat backbone P3
  - [-1, 3, C2f, [256]] # 15 (P3/8-small)

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]] # cat head P4
  - [-1, 3, C2f, [512]] # 18 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 9], 1, Concat, [1]] # cat head P5
  - [-1, 3, C2f, [1024]] # 21 (P5/32-large)

  - [[15, 18, 21], 1, Detect, [nc]] # Detect(P3, P4, P5)

```



yolov10åŸºäºyolov8æ”¹çš„ï¼Œä¸‹é¢çœ‹çœ‹æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Œ



å°†backboneçš„C2fåé¢ä¸¤å±‚å·ç§¯æ¢æˆäº†SCDownï¼Œå¦å¤–åŠ äº†ä¸€ä¸ªPSAæ¨¡å—ï¼Œ

å°†headçš„æœ€åä¸€ä¸ªC2fæ¢æˆC2fCIBï¼Œä»¥åŠå°†Detectæ¢æˆv10Detectï¼Œ

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726739894251-5c0f2542-06f9-40e5-906e-072869bde2d7.png)



<font style="color:#DF2A3F;">Yolov10çš„ä¸»è¦åˆ›æ–°ç‚¹æ˜¯å–æ¶ˆåå¤„ç†NMS</font>

NMS éæå¤§å€¼æŠ‘åˆ¶ï¼ˆNon-Maximum Suppresionï¼ŒNMSï¼‰



![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726740468124-fc129017-9f95-4f92-bda1-1af7716fa996.png)

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726740484959-474b4270-bac7-47c3-97f2-2b60efe3a73f.png)

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726740497396-e61a9277-5a3f-4e10-a028-358c7b0dde82.png)

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726740512429-66c6b1be-5626-4026-aa41-7152a6a70d6f.png)





## æ–¹æ³•1
  
 åƒyolov8éƒ¨ç½²é‚£ä¸ªä¸€æ ·é…ç½®ç¯å¢ƒè¯•ä¸€è¯•ï¼Œ

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726714620212-542fa492-f16c-43a1-b24b-d9e76352c6cf.png)

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726712148827-e82329cb-7e67-406b-aa26-4b98c79a6a1f.png)

 $(SolutionDir)$(Platform)\$(Configuration)\  
æ”¹ è¾“å‡ºç›®å½• $(SolutionDir)$(ProjectName)\$(Configuration)\  
 

é™„åŠ åŒ…å«ç›®å½• ./include/opencv;./include/CUDA;./include/onnxruntime;  
é™„åŠ åº“ç›®å½• ./lib  
é™„åŠ ä¾èµ–é¡¹ onnxruntime.lib;opencv_world481.lib

**è¿˜æ˜¯æŠ¥é”™ï¼Œä¸çŸ¥é“ä¸ºå•¥**

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726717665195-7ada4817-23f5-4c3b-a371-6d657cf344dc.png)





##   
æ–¹æ³•2ï¼ˆæˆåŠŸï¼‰
**<font style="color:#DF2A3F;">æ¢ç§æ–¹æ³•ï¼Œç›´æ¥vsé‡Œé¢å®‰è£…ä¾èµ–</font>**

**<font style="color:#DF2A3F;">æ–°å»ºé¡¹ç›®åï¼Œ</font>**

**å³é”®å¼•ç”¨**ï¼Œ

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726715656908-4f34a249-3698-482b-81c4-942a9ab32708.png)



![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726713639939-28ab76f1-6233-4228-9d76-a5d9557dc41c.png)

å…ˆå®‰è£…cpuç‰ˆæœ¬onnxruntimeè¯•ä¸€è¯•ï¼Œgpuç‰ˆæœ¬è¿˜è¦é…ç½®cuda

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726714109333-fdf63b6b-a307-4738-8dd9-601de861b65c.png)

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726714672962-e0c02c35-57c2-4821-8eaf-d11e7f954e78.png)

å®‰è£…å¥½åç”Ÿæˆpackage

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726714328138-843a8947-9165-40e3-9181-2da67a6f3d73.png)

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726714432999-e8efacc7-68ac-4273-955f-1ca547932ca0.png)

<font style="color:#DF2A3F;">å¯èƒ½æ˜¯ä¸å‰é¢æ‰‹åŠ¨é…ç½®çš„æœ‰å†²çª</font>

æ–°å»ºä¸€ä¸ªå·¥ç¨‹å†è¯•ä¸€è¯•ï¼Œ

```cpp
// yolov10_cpp.cpp : æ­¤æ–‡ä»¶åŒ…å« "main" å‡½æ•°ã€‚ç¨‹åºæ‰§è¡Œå°†åœ¨æ­¤å¤„å¼€å§‹å¹¶ç»“æŸã€‚
//

#include <iostream>
#include <onnxruntime_cxx_api.h>
#include <opencv2/opencv.hpp>

using std::cout;
using std::endl;
using std::vector;
using std::string;
using cv::Mat;

static const vector<std::string> class_name =
{ "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat", "traffic light",
"fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat", "dog", "horse", "sheep", "cow",
"elephant", "bear", "zebra", "giraffe", "backpack", "umbrella", "handbag", "tie", "suitcase", "frisbee",
"skis", "snowboard", "sports ball", "kite", "baseball bat", "baseball glove", "skateboard", "surfboard",
"tennis racket", "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple",
"sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair", "couch",
"potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse", "remote", "keyboard", "cell phone",
"microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors", "teddy bear",
"hair drier", "toothbrush" };

// å‰å¤„ç†
// æ¨ç†
// åå¤„ç†
// ä¸€æ¡ä¸€ç»´å‘é‡åŠ å½¢çŠ¶ä¿¡æ¯
// 640 * 640 * 3
// 
vector<float> img2vector(const Mat& img)
{
    vector<float> B;
    vector<float> G;
    vector<float> R;
    B.reserve(640 * 640 * 3);
    G.reserve(640 * 640);
    R.reserve(640 * 640);
    const uchar* pdata = (uchar*)img.datastart;
    for (int i = 0; i < img.dataend - img.datastart; i += 3)
        {
            B.push_back((float)*(pdata + i) / 255.0);
            G.push_back((float)*(pdata + i + 1) / 255.0);
            R.push_back((float)*(pdata + i + 2) / 255.0);
        }
    B.insert(B.cend(), G.cbegin(), G.cend());
    B.insert(B.cend(), R.cbegin(), R.cend());
    return B;
}

void print_float_data(const float* const pdata, int data_num_per_line = 6, int data_num = 300)
{
    for (int i = 0; i < data_num; i++)
        {
            for (int j = 0; j < data_num_per_line; j++)
                {
                    cout << *(pdata + i * data_num_per_line + j) << " ";
                }
            cout << endl;
        }
}

vector<vector<float>> float2vector(const float* const pdata, int data_num_per_line = 6, int data_num = 100, float conf = 0.8)
{
    vector<vector<float>> info;
    vector<float> info_line;
    for (int i = 0; i < data_num; i++)
        {
            if (*(pdata + i * data_num_per_line + 4) < conf)
            {
                continue;
            }
            for (int j = 0; j < data_num_per_line; j++)
                {
                    //cout << *(pdata + i * data_num_per_line + j) << " ";
                    info_line.push_back(*(pdata + i * data_num_per_line + j));
                }
            info.push_back(info_line);
            info_line.clear();
            //cout << endl;
        }
    return info;
}

void draw_box(Mat& img, const vector<vector<float>>& info)
{
    float w = img.cols;
    float h = img.rows;
    for (int i = 0; i < info.size(); i++)
        {
            cv::rectangle(img, cv::Point(info[i][0] * w / 640.0, info[i][1] * h / 640.0),
            cv::Point(info[i][2] * w / 640.0, info[i][3] * h / 640.0), cv::Scalar(0, 255, 0));
        string label;
        label += class_name[info[i][5]];
        label += "  ";
        std::stringstream oss;
        oss << info[i][4];
        label += oss.str();
        cv::putText(img, label, cv::Point(info[i][0] * w / 640.0, info[i][1] * h / 640.0), 1, 1, cv::Scalar(0, 255, 0), 2);

    }
}

int main()
{
    Ort::Env env;
    Ort::Session session(env, L"D:/studyFiles/VS-project/Visual studio community 2022 file/yolov10_cpp/models/yolov10n.onnx", Ort::SessionOptions{ nullptr });


    Mat src_img = cv::imread("D:/studyFiles/VS-project/Visual studio community 2022 file/yolov10_cpp/images/bus.jpg");
    Mat img;
    cv::resize(src_img, img, cv::Size(640, 640));
    vector<float> img_vector = img2vector(img);
    vector<int64_t> dim = { 1, 3, 640, 640 };
    Ort::Value input_tensor = Ort::Value::CreateTensor<float>(
        Ort::MemoryInfo::CreateCpu(OrtDeviceAllocator, OrtMemTypeCPU),
        img_vector.data(), img_vector.size(),
        dim.data(), dim.size()
    );
    vector<const char*> input_names = { "images" };
    vector<const char*> output_names = { "output0" };
    vector<Ort::Value> output_tensors = session.Run(Ort::RunOptions{ nullptr }, input_names.data(), &input_tensor,
        input_names.size(), output_names.data(), output_names.size());

    float* output = output_tensors[0].GetTensorMutableData<float>();
    //print_float_data(output);
    auto info = float2vector(output);

    draw_box(src_img, info);

    cv::imshow("test", src_img);
    cv::waitKey(0);

    std::cout << "Hello World!\n";
}

// è¿è¡Œç¨‹åº: Ctrl + F5 æˆ–è°ƒè¯• >â€œå¼€å§‹æ‰§è¡Œ(ä¸è°ƒè¯•)â€èœå•
// è°ƒè¯•ç¨‹åº: F5 æˆ–è°ƒè¯• >â€œå¼€å§‹è°ƒè¯•â€èœå•

// å…¥é—¨ä½¿ç”¨æŠ€å·§: 
//   1. ä½¿ç”¨è§£å†³æ–¹æ¡ˆèµ„æºç®¡ç†å™¨çª—å£æ·»åŠ /ç®¡ç†æ–‡ä»¶
//   2. ä½¿ç”¨å›¢é˜Ÿèµ„æºç®¡ç†å™¨çª—å£è¿æ¥åˆ°æºä»£ç ç®¡ç†
//   3. ä½¿ç”¨è¾“å‡ºçª—å£æŸ¥çœ‹ç”Ÿæˆè¾“å‡ºå’Œå…¶ä»–æ¶ˆæ¯
//   4. ä½¿ç”¨é”™è¯¯åˆ—è¡¨çª—å£æŸ¥çœ‹é”™è¯¯
//   5. è½¬åˆ°â€œé¡¹ç›®â€>â€œæ·»åŠ æ–°é¡¹â€ä»¥åˆ›å»ºæ–°çš„ä»£ç æ–‡ä»¶ï¼Œæˆ–è½¬åˆ°â€œé¡¹ç›®â€>â€œæ·»åŠ ç°æœ‰é¡¹â€ä»¥å°†ç°æœ‰ä»£ç æ–‡ä»¶æ·»åŠ åˆ°é¡¹ç›®
//   6. å°†æ¥ï¼Œè‹¥è¦å†æ¬¡æ‰“å¼€æ­¤é¡¹ç›®ï¼Œè¯·è½¬åˆ°â€œæ–‡ä»¶â€>â€œæ‰“å¼€â€>â€œé¡¹ç›®â€å¹¶é€‰æ‹© .sln æ–‡ä»¶

```

<font style="color:#DF2A3F;">åˆæŠ¥é”™ ç”±äºæ‰¾ä¸åˆ°hdf5.dll</font>

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726716080476-8d005cef-4515-47d8-a1d7-2d9d8cf61b71.png)



![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726720678008-47ca2cfa-66ef-438a-9bd4-2e6450b40619.png)

pythonçš„åº“æ–‡ä»¶ä¸­

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726721003979-f9af3e49-4573-491e-91e1-8f605b22baa5.png)

æ”¾å…¥System32æœ‰æ•ˆæœ

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726721934717-d6ded26b-811e-4964-a824-0f368f28ce89.png)

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1726722216470-9e9423dd-4a51-4621-8117-784793dcf7d2.png)



