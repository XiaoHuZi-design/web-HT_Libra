# 1、检测图像中物体大小
```plain
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 2024/2/9 11:47
# @Author  : LingJiaXiaoHu
# @File    : object_size.py
# @Software: win11 pytorch(GPU版本） python3.9.16

# 参照物 美分硬币宽度为0.955英寸（in)
# 注意根目录 命令 python object_size.py --image img.png --width 0.955

# coding=utf-8
# 导入一些后续需要使用到的python包
# 可能需要 pip install  imutils
from scipy.spatial import distance as dist
from imutils import perspective
from imutils import contours
import numpy as np
import argparse
import imutils
import cv2


# 定义一个中点函数，后面会用到
def midpoint(ptA, ptB):
    return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)


# 设置一些需要改变的参数
ap = argparse.ArgumentParser()
ap.add_argument("-i", "--image", required=True,
                help="path to the input image")
ap.add_argument("-w", "--width", type=float, required=True,
                help="width of the left-most object in the image (in inches)")
args = vars(ap.parse_args())

# 读取输入图片
image = cv2.imread(args["image"])
# 输入图片灰度化
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
# 对灰度图片执行高斯滤波
gray = cv2.GaussianBlur(gray, (7, 7), 0)

# 对滤波结果做边缘检测获取目标
edged = cv2.Canny(gray, 50, 100)
# 使用膨胀和腐蚀操作进行闭合对象边缘之间的间隙
edged = cv2.dilate(edged, None, iterations=1)
edged = cv2.erode(edged, None, iterations=1)

# 在边缘图像中寻找物体轮廓（即物体）
cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,
                        cv2.CHAIN_APPROX_SIMPLE)
cnts = imutils.grab_contours(cnts)

# 对轮廓按照从左到右进行排序处理
(cnts, _) = contours.sort_contours(cnts)
# 初始化 'pixels per metric'
pixelsPerMetric = None

# 循环遍历每一个轮廓
for c in cnts:
    # 如果当前轮廓的面积太少，认为可能是噪声，直接忽略掉
    if cv2.contourArea(c) < 100:
        continue

    # 根据物体轮廓计算出外切矩形框
    orig = image.copy()
    box = cv2.minAreaRect(c)
    box = cv2.cv.BoxPoints(box) if imutils.is_cv2() else cv2.boxPoints(box)
    box = np.array(box, dtype="int")

    # 按照top-left, top-right, bottom-right, bottom-left的顺序对轮廓点进行排序，并绘制外切的BB，用绿色的线来表示
    box = perspective.order_points(box)
    cv2.drawContours(orig, [box.astype("int")], -1, (0, 255, 0), 2)

    # 绘制BB的4个顶点，用红色的小圆圈来表示
    for (x, y) in box:
        cv2.circle(orig, (int(x), int(y)), 5, (0, 0, 255), -1)

    # 分别计算top-left 和top-right的中心点和bottom-left 和bottom-right的中心点坐标
    (tl, tr, br, bl) = box
    (tltrX, tltrY) = midpoint(tl, tr)
    (blbrX, blbrY) = midpoint(bl, br)

    # 分别计算top-left和top-right的中心点和top-righ和bottom-right的中心点坐标
    (tlblX, tlblY) = midpoint(tl, bl)
    (trbrX, trbrY) = midpoint(tr, br)

    # 绘制BB的4条边的中心点，用蓝色的小圆圈来表示
    cv2.circle(orig, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)
    cv2.circle(orig, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)
    cv2.circle(orig, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)
    cv2.circle(orig, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)

    # 在中心点之间绘制直线，用紫红色的线来表示
    cv2.line(orig, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),
             (255, 0, 255), 2)
    cv2.line(orig, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),
             (255, 0, 255), 2)

    # 计算两个中心点之间的欧氏距离，即图片距离
    dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))
    dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))

    # 初始化测量指标值，参考物体在图片中的宽度已经通过欧氏距离计算得到，参考物体的实际大小已知
    if pixelsPerMetric is None:
        pixelsPerMetric = dB / args["width"]

    # 计算目标的实际大小（宽和高），用英尺来表示
    dimA = dA / pixelsPerMetric
    dimB = dB / pixelsPerMetric

    # 在图片中绘制结果
    cv2.putText(orig, "{:.1f}in".format(dimA),
                (int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,
                0.65, (255, 255, 255), 2)
    cv2.putText(orig, "{:.1f}in".format(dimB),
                (int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,
                0.65, (255, 255, 255), 2)

    # 显示结果
    cv2.imshow("Image", orig)
    cv2.waitKey(0)

```

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1725191348828-486f4bac-8cbb-4b9c-acf0-1d9868614643.png)

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1725191379923-b60323af-b785-47f0-ad78-c7bf7e28177a.png)

附源代码：[img.png](https://www.yuque.com/attachments/yuque/0/2024/png/39216292/1725191396935-9f62a749-2ce8-4f3e-88ca-e51da5110e37.png)[object_size.py](https://www.yuque.com/attachments/yuque/0/2024/py/39216292/1725191396468-62ccbed9-77c1-4a53-ad6f-042b165f2e0a.py)



```python
import cv2
import utlis

###################################
webcam = False # 是否打开电脑自带摄像头或外置摄像头进行实时尺寸推算，如果想要进行实时，将False修改为True即可
path = '1.jpg' # 存放调用文件的路径
cap = cv2.VideoCapture(0)
cap.set(10, 160)
cap.set(3, 1920)
cap.set(4, 1080)
# A4纸的缩放版本 放大3倍 像素太小会丢失很多细节   21cm×29.7cm(210mm×297mm)
scale = 3
wP = 210*scale
hP = 297*scale
###################################

while True:
    if webcam:success,img = cap.read()
    else: img = cv2.imread(path)

    # 加1行  缩小点
    img = cv2.resize(img, (0, 0), None, 0.5, 0.5)

    imgContours , conts = utlis.getContours(img, showCanny=True, minArea=50000, filter=4, draw = False)
    if len(conts) != 0:
        biggest = conts[0][2]
        #print(biggest)
        imgWarp = utlis.warpImg(img, biggest, wP,hP)
        imgContours2, conts2 = utlis.getContours(imgWarp,
                                                 minArea=2000, filter=4,
                                                 cThr=[50,50],draw = False)
        if len(conts) != 0:
            for obj in conts2:
                cv2.polylines(imgContours2,[obj[2]],True,(0,255,0),2)
                nPoints = utlis.reorder(obj[2])
                nW = round((utlis.findDis(nPoints[0][0]//scale,nPoints[1][0]//scale)/10),1)
                nH = round((utlis.findDis(nPoints[0][0]//scale,nPoints[2][0]//scale)/10),1)
                cv2.arrowedLine(imgContours2, (nPoints[0][0][0], nPoints[0][0][1]), (nPoints[1][0][0], nPoints[1][0][1]),
                                (255, 0, 255), 3, 8, 0, 0.05)
                cv2.arrowedLine(imgContours2, (nPoints[0][0][0], nPoints[0][0][1]), (nPoints[2][0][0], nPoints[2][0][1]),
                                (255, 0, 255), 3, 8, 0, 0.05)
                x, y, w, h = obj[3]
                cv2.putText(imgContours2, '{}cm'.format(nW), (x + 30, y - 10), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.5,
                            (255, 0, 255), 2)
                cv2.putText(imgContours2, '{}cm'.format(nH), (x - 70, y + h // 2), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1.5,
                            (255, 0, 255), 2)
        cv2.imshow('A4', imgContours2)

    img = cv2.resize(img,(0,0),None,0.5,0.5)
    cv2.imshow('Original',img)
    cv2.waitKey(1)
```

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1725190334523-5ac84a08-73ba-46f6-b1e8-24ffc1764364.png)![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1725190280960-62331b75-d9f8-4c0c-864d-49e21bee9552.png)![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1725190296993-5d0cabc5-45d3-4e3a-a59b-fc277f6599b7.png)

附源代码：[1.jpg](https://www.yuque.com/attachments/yuque/0/2024/jpeg/39216292/1725190474794-0ab50455-30ba-4c01-8b29-fb6ac893cab8.jpeg)[3.jpg](https://www.yuque.com/attachments/yuque/0/2024/jpeg/39216292/1725190474842-ef64ba98-c337-472f-a2fe-eafb004bf49e.jpeg)[ObjectMeasurement.py](https://www.yuque.com/attachments/yuque/0/2024/py/39216292/1725190474747-62e8f688-ec6a-4c5e-8410-defa5d181d5e.py)[README.md](https://www.yuque.com/attachments/yuque/0/2024/md/39216292/1725190474780-d1bc9f8c-45ca-4716-b802-a55a945d4f9b.md)[Thumbnail.gif](https://www.yuque.com/attachments/yuque/0/2024/gif/39216292/1725190475809-0acb0152-d4d1-433e-88a4-9497b79b1b91.gif)[utlis.py](https://www.yuque.com/attachments/yuque/0/2024/py/39216292/1725190475101-78ce857f-75ad-4a52-8272-c7f9ccbab19d.py)



```python
import cv2
import numpy as np
cap=cv2.VideoCapture("Coin2.mp4")

while(cap.read()) :
    ref,frame = cap.read()
    roi=frame[:1080,0:1920]

    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
    gray_blur=cv2.GaussianBlur(gray,(15,15),0)
    thresh=cv2.adaptiveThreshold(gray_blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,11,1)
    kernel=np.ones((3,3),np.uint8)
    closing=cv2.morphologyEx(thresh,cv2.MORPH_CLOSE,kernel,iterations=4)

    result_img=closing.copy()
    contours,hierachy=cv2.findContours(result_img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
    counter=0
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area<5000 or area > 35000:
            continue
        ellipse = cv2.fitEllipse(cnt)
        cv2.ellipse(roi,ellipse,(0,255,0),2)
        counter+=1

    cv2.putText(roi,str(counter),(10,100),cv2.FONT_HERSHEY_SIMPLEX,4,(255,0,0),2,cv2.LINE_AA)
    cv2.imshow("Show",roi)

    if cv2.waitKey(1) & 0xFF==ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1725191182535-35df4511-d8ba-4ff9-9431-79e2df260651.png)

附源代码：

[Coin2.mp4](https://www.yuque.com/attachments/yuque/0/2024/mp4/39216292/1725191257719-4581bfe4-0c82-4003-b288-dbca30ed19c9.mp4)[CoinDetection.py](https://www.yuque.com/attachments/yuque/0/2024/py/39216292/1725191248846-b60364b1-6176-46da-8f47-a64e64a13318.py)[README.md](https://www.yuque.com/attachments/yuque/0/2024/md/39216292/1725191248893-1b3522a4-6519-4767-bbd1-6e7f3afc0fef.md)

# 2、识别手掌距离
```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 2024/2/23 11:27
# @Author  : LingJiaXiaoHu
# @File    : main.py
# @Software: win11 pytorch(GPU版本） python3.9.16

'''
import cv2
from cvzone.HandTrackingModule import HandDetector
import math
import numpy as np
import cvzone

# Webcam
cap = cv2.VideoCapture(0)
cap.set(3, 1280)
cap.set(4, 720)

# Hand Detector
detector = HandDetector(detectionCon=0.8, maxHands=1)

# Find Function
# x is the raw distance y is the value in cm
x = [300, 245, 200, 170, 145, 130, 112, 103, 93, 87, 80, 75, 70, 67, 62, 59, 57]
y = [20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]
coff = np.polyfit(x, y, 2)  # y = Ax^2 + Bx + C

# Loop
while True:
    success, img = cap.read()
    hands = detector.findHands(img, draw=False)
    print(hands)

    if hands:
        lmList = hands[0]['lmList']
        x, y, w, h = hands[0]['bbox']
        x1, y1 = lmList[5]
        x2, y2 = lmList[17]

        distance = int(math.sqrt((y2 - y1) ** 2 + (x2 - x1) ** 2))
        A, B, C = coff
        distanceCM = A * distance ** 2 + B * distance + C

        # print(distanceCM, distance)

        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 3)
        cvzone.putTextRect(img, f'{int(distanceCM)} cm', (x+5, y-10))

    cv2.imshow("Image", img)
    cv2.waitKey(1)
'''

#改进一下

import cv2
from cvzone.HandTrackingModule import HandDetector
import math
import numpy as np
import cvzone

# Webcam
cap = cv2.VideoCapture(0)
cap.set(3, 1280)
cap.set(4, 720)

# Hand Detector
detector = HandDetector(detectionCon=0.8, maxHands=1)

# Find Function
# x is the raw distance y is the value in cm
x = [300, 245, 200, 170, 145, 130, 112, 103, 93, 87, 80, 75, 70, 67, 62, 59, 57]
y = [20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]
coff = np.polyfit(x, y, 2)  # y = Ax^2 + Bx + C

# Loop
while True:

    success, img = cap.read()
    #hands, img = detector.findHands(img)
    hands, img = detector.findHands(img, draw=False)  #不显示骨骼图


    if hands:
        lmList = hands[0]['lmList']
        print(lmList)

        #x1, y1 = lmList[5]   #报错 多于两个的值解包到两个变量  多余的值可以使用额外变量extra_value 或 占位符_ 接收
        x1, y1, _ = lmList[5]
        #x2, y2 = lmList[17]
        x2, y2, _ = lmList[17]

        distance = int(math.sqrt((y2 - y1) ** 2 + (x2 - x1) ** 2))
        print(abs(x2 - x1), distance)

        A, B, C = coff
        distanceCM = A * distance ** 2 + B * distance + C
        print(distanceCM, distance)

        x, y, w, h = hands[0]['bbox']
        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 3)     #画边界框 注释可以去掉
        cvzone.putTextRect(img, f'{int(distanceCM)} cm', (x + 5, y - 10))

    cv2.imshow("Image", img)
    cv2.waitKey(1)

cap.release()
cv2.destroyAllWindows()
```

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1725190574494-feb2c454-bf5c-46fa-9be4-8fa0386c806f.png)



```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 2024/2/23 11:27
# @Author  : LingJiaXiaoHu
# @File    : Game.py
# @Software: win11 pytorch(GPU版本） python3.9.16


import random
import cv2
from cvzone.HandTrackingModule import HandDetector
import math
import numpy as np
import cvzone
import time

# Webcam
cap = cv2.VideoCapture(0)
cap.set(3, 1280)
cap.set(4, 720)

# Hand Detector
detector = HandDetector(detectionCon=0.8, maxHands=1)

# Find Function
# x is the raw distance y is the value in cm
x = [300, 245, 200, 170, 145, 130, 112, 103, 93, 87, 80, 75, 70, 67, 62, 59, 57]
y = [20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]
coff = np.polyfit(x, y, 2)  # y = Ax^2 + Bx + C

# Game Variables
cx, cy = 250, 250
color = (255, 0, 255)
counter = 0
score = 0
timeStart = time.time()
totalTime = 20

# Loop
while True:
    success, img = cap.read()
    img = cv2.flip(img, 1)

    if time.time()-timeStart < totalTime:

        hands, img = detector.findHands(img, draw=False)

        if hands:
            lmList = hands[0]['lmList']
            x, y, w, h = hands[0]['bbox']
            x1, y1, _ = lmList[5]
            x2, y2, _ = lmList[17]

            distance = int(math.sqrt((y2 - y1) ** 2 + (x2 - x1) ** 2))
            A, B, C = coff
            distanceCM = A * distance ** 2 + B * distance + C
            # print(distanceCM, distance)

            if distanceCM < 40:
                if x < cx < x + w and y < cy < y + h:
                    counter = 1
            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 3)
            cvzone.putTextRect(img, f'{int(distanceCM)} cm', (x + 5, y - 10))

        if counter:
            counter += 1
            color = (0, 255, 0)
            if counter == 3:
                cx = random.randint(100, 1100)
                cy = random.randint(100, 600)
                color = (255, 0, 255)
                score +=1
                counter = 0

        # Draw Button
        cv2.circle(img, (cx, cy), 30, color, cv2.FILLED)
        cv2.circle(img, (cx, cy), 10, (255, 255, 255), cv2.FILLED)
        cv2.circle(img, (cx, cy), 20, (255, 255, 255), 2)
        cv2.circle(img, (cx, cy), 30, (50, 50, 50), 2)

        # Game HUD
        cvzone.putTextRect(img, f'Time: {int(totalTime-(time.time()-timeStart))}',
                           (1000, 75), scale=3, offset=20)
        cvzone.putTextRect(img, f'Score: {str(score).zfill(2)}', (60, 75), scale=3, offset=20)
    else:
        cvzone.putTextRect(img, 'Game Over', (400, 400), scale=5, offset=30, thickness=7)
        cvzone.putTextRect(img, f'Your Score: {score}', (450, 500), scale=3, offset=20)
        cvzone.putTextRect(img, 'Press R to restart', (460, 575), scale=2, offset=10)



    cv2.imshow("Image", img)
    key = cv2.waitKey(1)

    if key == ord('r'):
        timeStart = time.time()
        score = 0

```

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1725190751075-d3476faa-97bb-4847-97d6-a6daff2315f1.png)

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1725190822995-49c743de-68a0-4050-95f9-ff9d0993ef35.png)



附源代码：[Game.py](https://www.yuque.com/attachments/yuque/0/2024/py/39216292/1725190883825-96732a17-b485-4d86-8e2d-a77ba67e67da.py)[main.py](https://www.yuque.com/attachments/yuque/0/2024/py/39216292/1725190883804-0dae20ef-981b-49ed-9d5f-e0e49c72d709.py)

# 3、识别人脸距离
```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 2024/2/23 11:34
# @Author  : LingJiaXiaoHu
# @File    : FaceDepthMeasurement.py
# @Software: win11 pytorch(GPU版本） python3.9.16

import cv2
import cvzone
from cvzone.FaceMeshModule import FaceMeshDetector

cap = cv2.VideoCapture(0)
detector = FaceMeshDetector(maxFaces=1)

while True:
    success, img = cap.read()
    img, faces = detector.findFaceMesh(img, draw=False)

    if faces:
        face = faces[0]
        pointLeft = face[145]
        pointRight = face[374]
        # Drawing
        # cv2.line(img, pointLeft, pointRight, (0, 200, 0), 3)
        # cv2.circle(img, pointLeft, 5, (255, 0, 255), cv2.FILLED)
        # cv2.circle(img, pointRight, 5, (255, 0, 255), cv2.FILLED)
        w, _ = detector.findDistance(pointLeft, pointRight)
        W = 6.3

        # # Finding the Focal Length
        # d = 50
        # f = (w*d)/W
        # print(f)

        # Finding distance
        f = 840
        d = (W * f) / w
        print(d)

        cvzone.putTextRect(img, f'Depth: {int(d)}cm',
                           (face[10][0] - 100, face[10][1] - 50),
                           scale=2)

    cv2.imshow("Image", img)
    cv2.waitKey(1)
```

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1725190956305-03d45f0f-2fb7-49a5-92d1-4fce97a8476b.png)



```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 2024/2/23 11:35
# @Author  : LingJiaXiaoHu
# @File    : DynamicTextReader.py
# @Software: win11 pytorch(GPU版本） python3.9.16


import cv2
import cvzone
from cvzone.FaceMeshModule import FaceMeshDetector
import numpy as np

cap = cv2.VideoCapture(0)
detector = FaceMeshDetector(maxFaces=1)

textList = ["Welcome to ", "Murtaza's Workshop.",
            "Here we will study", "Computer Vision,", "Robotics and AI.",
            "If you like this video", "Like, Share", "and Subscribe."]

sen = 25  # more is less

while True:
    success, img = cap.read()
    imgText = np.zeros_like(img)
    img, faces = detector.findFaceMesh(img, draw=False)

    if faces:
        face = faces[0]
        pointLeft = face[145]
        pointRight = face[374]
        w, _ = detector.findDistance(pointLeft, pointRight)
        W = 6.3

        # Finding distance
        f = 840
        d = (W * f) / w
        print(d)

        cvzone.putTextRect(img, f'Depth: {int(d)}cm',
                           (face[10][0] - 100, face[10][1] - 50),
                           scale=2)

        for i, text in enumerate(textList):
            singleHeight = 20 + int((int(d/sen)*sen)/4)
            scale = 0.4 + (int(d/sen)*sen)/75
            cv2.putText(imgText, text, (50, 50 + (i * singleHeight)),
                        cv2.FONT_ITALIC, scale, (255, 255, 255), 2)

    imgStacked = cvzone.stackImages([img, imgText], 2, 1)
    cv2.imshow("Image", imgStacked)
    cv2.waitKey(1)
```

![](https://cdn.nlark.com/yuque/0/2024/png/39216292/1725191051488-d7730a80-05ba-4703-b686-5e93d2976792.png)



附源代码：[Distance-Measurement.png](https://www.yuque.com/attachments/yuque/0/2024/png/39216292/1725191096182-004cd3c2-698e-4bb6-9a33-0b330515276e.png)[DynamicTextReader.py](https://www.yuque.com/attachments/yuque/0/2024/py/39216292/1725191096118-c0121716-25bc-4efa-b7b3-0195fe36cceb.py)[FaceDepthMeasurement.py](https://www.yuque.com/attachments/yuque/0/2024/py/39216292/1725191096205-252a242a-cd4b-4435-a506-19707188a934.py)





